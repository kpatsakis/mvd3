bool prepareToEmitMIR(const VarTypeVector& argTypes) alloc_ = lifo_ . new_ < TempAllocator > ( & lifo_ ); graph_ = lifo_ . new_ < MIRGraph > ( alloc_ ); info_ = lifo_ . new_ < CompileInfo > ( locals_ . count ( ) ); const OptimizationInfo * optimizationInfo = js_IonOptimizations . get ( Optimization_AsmJS ) ; const JitCompileOptions options ; mirGen_ = lifo_ . new_ < MIRGenerator > ( CompileCompartment :: get ( cx ( ) -> compartment ( ) ) , options , alloc_ , graph_ , info_ , optimizationInfo ); return cx_ ; ExclusiveContext* cx() const if ( ! newBlock ( nullptr , & curBlock_ , fn_ ) )  bool newBlock(MBasicBlock* pred, MBasicBlock** block, ParseNode* pn) return newBlockWithDepth ( pred , loopStack_ . length ( ) , block , pn ) ; bool newBlockWithDepth(MBasicBlock* pred, unsigned loopDepth, MBasicBlock** block, ParseNode* pn) * block = MBasicBlock :: NewAsmJS ( mirGraph ( ) , info ( ) , pred , MBasicBlock :: NORMAL ); CompileInfo &  info() const return * info_ ; MIRGraph &     mirGraph() const return * graph_ ; if ( ! * block )  return false ; return true ; for (ABIArgTypeIter i(argTypes); !i.done(); i++) if ( ! mirGen_ -> ensureBallast ( ) )  for (unsigned i = 0; i < varInitializers_.length(); i++) AsmJSNumLit & lit = varInitializers_ [ i ] ; MIRType type = Type :: Of ( lit ) . toMIRType ( ) ; MIRType toMIRType() const switch ( which_ )  return MIRType_Double ; return MIRType_Float32 ; return MIRType_Int32 ; return MIRType_Int32x4 ; return MIRType_Float32x4 ; return MIRType_None ; MInstruction * ins ; if ( lit . isSimd ( ) )  ins = MConstant :: NewAsmJS ( alloc ( ) , lit . scalarValue ( ) , type ); return * alloc_ ; TempAllocator &     alloc() const curBlock_ -> add ( ins ); curBlock_ -> initSlot ( info ( ) . localSlot ( firstLocalSlot + i ) , ins ); CompileInfo &  info() const MOZ_ASSERT ( info_ ); CompileInfo &  info() const return * info_ ; if ( ! mirGen_ -> ensureBallast ( ) )  